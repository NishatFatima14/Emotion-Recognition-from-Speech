# 🎙️ Emotion Recognition from Speech (CodeAlpha Internship Project)

This project uses deep learning and speech processing to classify emotions from audio files.

## 🔧 Technologies Used
- Python
- Librosa
- TensorFlow / Keras
- Scikit-learn
- Matplotlib / Seaborn

## 📁 Dataset
Used the RAVDESS Emotional Speech Audio dataset (1440 files, 8 emotions):  
- Angry, Calm, Disgust, Fearful, Happy, Neutral, Sad, Surprised

## 🧠 Model
- Extracted MFCC features (40 per audio)
- Built a CNN model with:
  - 2 Conv1D layers
  - MaxPooling & Dropout
  - Fully Connected Softmax output
- Final test accuracy: **✅ 87.6%** (example)
- Confusion matrix & classification report included

---

## 🎥 LinkedIn Video

📌 [LinkedIn Video Demo](https://linkedin.com/in/your-link-here)  
Explains dataset, model training, and real-time performance.

## 📌 Submitted To

This project was submitted as part of my **Machine Learning Internship** with **CodeAlpha** (June–July 2025).

---

## 🙋‍♀️ Author

- **Nishat Fatima**
- GitHub: [@nishatfatima](https://github.com/NishatFatima14)
- LinkedIn: [Nishat Fatima](https://www.linkedin.com/in/nishat-fatima-ai-dev/)
